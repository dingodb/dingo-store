// Copyright (c) 2023 dingodb.com, Inc. All Rights Reserved
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

import "common.proto";
import "error.proto";

package dingodb.pb.store;

option java_package = "io.dingodb.store";
option cc_generic_services = true;

message Context {
  int64 region_id = 1;
  dingodb.pb.common.RegionEpoch region_epoch = 2;
  IsolationLevel isolation_level = 7;
}

message KvGetRequest {
  Context context = 1;
  bytes key = 2;
}

message KvGetResponse {
  dingodb.pb.error.Error error = 1;
  bytes value = 2;
}

message KvBatchGetRequest {
  Context context = 1;
  repeated bytes keys = 2;
}

message KvBatchGetResponse {
  dingodb.pb.error.Error error = 1;
  repeated dingodb.pb.common.KeyValue kvs = 2;
}

message KvPutRequest {
  Context context = 1;
  dingodb.pb.common.KeyValue kv = 2;
}

message KvPutResponse {
  dingodb.pb.error.Error error = 1;
}

message KvBatchPutRequest {
  Context context = 1;
  repeated dingodb.pb.common.KeyValue kvs = 2;
}

message KvBatchPutResponse {
  dingodb.pb.error.Error error = 1;
}

message KvPutIfAbsentRequest {
  Context context = 1;
  dingodb.pb.common.KeyValue kv = 2;
}

message KvPutIfAbsentResponse {
  dingodb.pb.error.Error error = 1;
  // key_state = true, update success
  // key_state = false, update failed
  bool key_state = 2;
}

message KvBatchPutIfAbsentRequest {
  Context context = 1;
  repeated dingodb.pb.common.KeyValue kvs = 2;
  bool is_atomic = 3;
}

message KvBatchPutIfAbsentResponse {
  dingodb.pb.error.Error error = 1;
  // return the execution status of each key
  // key_states[index] = true, update success
  // key_states[index] = false, update failed
  repeated bool key_states = 2;
}

message KvBatchDeleteRequest {
  Context context = 1;
  repeated bytes keys = 2;
}

message KvBatchDeleteResponse {
  dingodb.pb.error.Error error = 1;
  // return the execution status of each key
  // key_states[index] = true, delete success
  // key_states[index] = false, key not exist
  repeated bool key_states = 2;
}

message KvDeleteRangeRequest {
  Context context = 1;
  dingodb.pb.common.RangeWithOptions range = 2;
}

message KvDeleteRangeResponse {
  dingodb.pb.error.Error error = 1;
  int64 delete_count = 2;
}

message KvCompareAndSetRequest {
  Context context = 1;
  dingodb.pb.common.KeyValue kv = 2;
  // empty means key not exist
  bytes expect_value = 3;
}

message KvCompareAndSetResponse {
  dingodb.pb.error.Error error = 1;
  // key_state = true, update success
  // key_state = false, update failed
  bool key_state = 2;
}

message KvBatchCompareAndSetRequest {
  Context context = 1;
  repeated dingodb.pb.common.KeyValue kvs = 2;
  // empty means key not exist
  repeated bytes expect_values = 3;
  bool is_atomic = 4;
}

message KvBatchCompareAndSetResponse {
  dingodb.pb.error.Error error = 1;
  // key_state = true, update success
  // key_state = false, update failed
  repeated bool key_states = 2;
}

// aggregation type
enum AggregationType {
  AGGREGATION_NONE = 0;
  SUM = 1;
  COUNT = 2;
  COUNTWITHNULL = 3;  // null is counted in count //TODO
  MAX = 4;
  MIN = 5;
  SUM0 = 6;
}

// aggregation operation
message AggregationOperator {
  // aggregation operator
  AggregationType oper = 1;

  // Specify the index column here is currently only specifying a certain column.
  // such as 0, 1 (-1 = all)
  int32 index_of_column = 2;
}

message Schema {
  enum Type {
    BOOL = 0;
    INTEGER = 1;
    FLOAT = 2;
    LONG = 3;
    DOUBLE = 4;
    STRING = 5;
    BOOLLIST = 6;
    INTEGERLIST = 7;
    FLOATLIST = 8;
    LONGLIST = 9;
    DOUBLELIST = 10;
    STRINGLIST = 11;
  };

  // type of data
  Type type = 1;

  // Is primary key
  bool is_key = 2;

  // is allowed to be empty
  bool is_nullable = 3;

  // index position starts from 0
  int32 index = 4;
}

message Coprocessor {
  // the version of the serialized data
  int32 schema_version = 1;

  message SchemaWrapper {
    repeated Schema schema = 1;
    int64 common_id = 2;
  }

  // original schema
  SchemaWrapper original_schema = 2;

  // return schema
  SchemaWrapper result_schema = 3;

  // Column selection in the table list selection
  // For example, [0, 2, 4, 7] selects the index subscript of the column.
  // If the length of the array is 0, it means all
  repeated int32 selection_columns = 4;

  // The operator pushes down the expression binary filter to use empty to indicate that there is no expression and no
  // filtering
  bytes expression = 5;

  // It is allowed to be empty, indicating that there is no group by. For example, group by name, age; [0, 1]
  repeated int32 group_by_columns = 6;

  // group by expression
  // The list that needs to be aggregated is allowed to be empty, that is, not aggregated sum(salary), count(age),
  // count(salary). but group_by_columns is not allowed to be empty
  repeated AggregationOperator aggregation_operators = 7;
}

message KvScanBeginRequest {
  // region id
  Context context = 1;

  // prefix start_key end_key with mode
  dingodb.pb.common.RangeWithOptions range = 2;

  // The maximum number of requests keys per request
  // limit = 0 means only scan_id is returned and no data is returned
  // If max_fetch_cnt > 0, it means to return scan_id and data. Note that in this way, the return will be slower because
  // the data needs to be prepared For example: max_fetch_cnt = 10000, which means that the maximum number of kv items
  // in this request is 10000, which is just a suggested value. If the maximum number of kv items in the server is 1000,
  // The data returned each time is only 1000 pieces of data. Note: only the maximum number of kv pairs per request
  int64 max_fetch_cnt = 3;

  // is it just to get the key
  bool key_only = 4;

  // whether to automatically release resources
  // after reading all the data, the default is false,
  // and the default is automatically released
  bool disable_auto_release = 5;

  // Whether to enable operator pushdown, enabled by default (false: means enabled, true: means disabled)
  bool disable_coprocessor = 6;

  // coprocessor
  Coprocessor coprocessor = 7;
}

message KvScanBeginResponse {
  // error code
  dingodb.pb.error.Error error = 1;

  // uniquely identifies this scan
  bytes scan_id = 2;

  // return key value pair. if kvs.size == 0 means no data
  repeated dingodb.pb.common.KeyValue kvs = 3;
}

message KvScanContinueRequest {
  // region id
  Context context = 1;

  // uniquely identifies this scan
  bytes scan_id = 2;

  // The maximum number of requests keys per request
  // If max_fetch_cnt > 0, it means to return scan_id and data. Note that in this way, the return will be slower because
  // the data needs to be prepared For example: max_fetch_cnt = 10000, which means that the maximum number of kv items
  // in this request is 10000, which is just a suggested value. If the maximum number of kv items in the server is 1000,
  // The data returned each time is only 1000 pieces of data. Note: only the maximum number of kv pairs per request
  int64 max_fetch_cnt = 3;
}

message KvScanContinueResponse {
  // error code
  dingodb.pb.error.Error error = 1;

  // return key value pair. if kvs.size == 0 means no data
  repeated dingodb.pb.common.KeyValue kvs = 2;
}

message KvScanReleaseRequest {
  // region id
  Context context = 1;

  // uniquely identifies this scan
  bytes scan_id = 2;
}

message KvScanReleaseResponse {
  // error code
  dingodb.pb.error.Error error = 1;
}

enum IsolationLevel {
  InvalidIsolationLevel = 0;  // this is just a placeholder, not a valid isolation level
  SnapshotIsolation = 1;
  ReadCommitted = 2;
}

enum Action {
  NoAction = 0;
  TTLExpireRollback = 1;
  LockNotExistRollback = 2;
  MinCommitTSPushed = 3;
  TTLExpirePessimisticRollback = 4;
  LockNotExistDoNothing = 5;
}

message LockInfo {
  bytes primary_lock = 1;  // the primary lock of the transaction
  int64 lock_ts = 2;       // the start_ts of the transaction
  bytes key = 3;           // the key of the lock
  int64 lock_ttl = 4;      // the lock ttl timestamp in milisecond
  int64 txn_size = 5;      // the number of keys involved in the transaction
  Op lock_type = 6;        // the type of the lock, it can be put, delete, lock
  bytes short_value = 7;   // the short value will persist to lock_info, and do not write data, commit will set it to
                           // write_info.short_value
}

message WriteInfo {
  int64 start_ts = 1;
  Op op = 2;
  bytes short_value = 3;
}

enum Op {
  None = 0;         // just a placeholder
  Put = 1;          // prewrite: do data upsert, like KvPut or VectorAdd
  Delete = 2;       // prewrite: do data delete, like KvDelete or VectorDelete
  PutIfAbsent = 3;  // prewrite: do insert, if id is exists, return AlreadyExist error
  Rollback = 4;     // rollback: only do rollback
  Lock = 5;         // pessimistic lock: do lock
}

message Mutation {
  Op op = 1;
  bytes key = 2;
  bytes value = 3;
}

message WriteConflict {
  enum Reason {
    Unknown = 0;
    Optimistic = 1;        // in optimistic transactions.
    PessimisticRetry = 2;  // a lock acquisition request waits for a lock and awakes, or meets a
                           // newer version of data, let Executor retry.
    SelfRolledBack = 3;    // the transaction itself has been rolled back when it
                           // tries to prewrite.
    RcCheckTs = 4;         // RcCheckTs failure by meeting a newer version, let Executor retry.
    // LazyUniquenessCheck = 5;  // write conflict found in lazy uniqueness check in
    //                           // pessimistic transactions.
  }

  Reason reason = 1;
  int64 start_ts = 2;
  int64 conflict_ts = 3;         // the lock_ts conflicted with start_ts
  int64 conflict_commit_ts = 4;  // the commit_ts of the transaction which meets read conflict
  bytes key = 5;
  bytes primary_key = 6;  // the conflict lock's primary key
}

message TxnNotFound {
  int64 start_ts = 1;
  bytes primary_key = 2;
}

message PrimaryMismatch {
  LockInfo lock_info = 1;
}

message AlreadyExist {
  bytes key = 1;
}

message TxnResultInfo {
  // Client should backoff or cleanup the lock then retry, this error occurs in get phase.
  LockInfo locked = 1;
  // Write conflict with key which is locked by another transaction, this error occurs in prewrite phase.
  WriteConflict write_conflict = 2;
  // Txn not found when checking txn status.
  TxnNotFound txn_not_found = 3;
  // CheckTxnStatus is sent to a lock that's not the primary.
  PrimaryMismatch primary_mismatch = 4;
}

// TxnGet do point-lookup a value for key in the transaction with start_ts
message TxnGetRequest {
  Context context = 1;
  // the key client want to do get
  bytes key = 2;
  // the start_ts of the get transaction, store will return the value of the key when commit_ts < start_ts
  int64 start_ts = 3;
}

message TxnGetResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  // A value could not be retrieved due to the state of the database for the
  // requested key.
  // the txn_result is one of the following:
  // 1. LockInfo: Read conflict with key which is locked by another transaction. The client should backoff or cleanup
  // the lock then retry.
  // 2. otherwise, txn_result is empty
  TxnResultInfo txn_result = 2;
  // The value associated with the key, if not found, is empty and error is NOT_FOUND
  // dingo-store do not accept NULL value, so if value is NULL, it means the key is not exist
  bytes value = 3;
  // True if the key does not exist in the database.
  // bool not_found = 4;
}

// TxnScan fetches values for a range of keys in the transaction with start_ts.
message TxnScanRequest {
  Context context = 1;
  // prefix start_key end_key with mode
  dingodb.pb.common.RangeWithOptions range = 2;

  // The maximum number of results to return.
  uint32 limit = 4;
  // the start_ts of the get transaction, store will return the value of the key when commit_ts < start_ts
  int64 start_ts = 5;
  // Return only the keys found by scanning, not their values.
  bool key_only = 6;
  // For compatibility, when scanning forward, the range to scan is [start_key, end_key), where start_key < end_key;
  // and when scanning backward, it scans [end_key, start_key) in descending order, where end_key < start_key.
  bool is_reverse = 7;  // NOT_IMPLEMENTED
}

// TxnScan can be partially success
// if kvs is not null, and has_more is true, means scan is not finished, client should continue to scan from end_key.
// if txn_result is not null, the kvs may not null, client can use kvs as a partial result, and should continue to scan
// after resolve lock.
message TxnScanResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  // This txn_result exists when some key is locked but we cannot check locks of
  // all keys. In this case, `kvs` should be empty and the client should redo
  // scanning all the keys after resolving the lock.
  // the txn_result is one of the following:
  // 1. LockInfo: Read conflict with key which is locked by another transaction.
  // 2. otherwise, txn_result is empty
  TxnResultInfo txn_result = 2;
  // kvs is the return value of the scan request
  repeated dingodb.pb.common.KeyValue kvs = 3;
  // if scan is not finished, has_more is true, otherwise false
  bool has_more = 4;
  // the last iteratered key of this scan response.
  // if end_key is null, means scan do not successfully iterate any key.
  bytes end_key = 5;
}

// Lock a set of keys to prepare to write to them.
message PessimisticLockRequest {
  Context context = 1;
  // In this case every `Op` of the mutations must be `PessimisticLock`.
  repeated Mutation mutations = 2;
  bytes primary_lock = 3;
  uint64 start_ts = 4;
  // the lock's ttl is timestamp in milisecond, it's the absolute timestamp when the lock is expired.
  uint64 lock_ttl = 5;
  // Each locking command in a pessimistic transaction has its own timestamp.
  // If locking fails, then the corresponding SQL statement can be retried with a later timestamp, Executor does not
  // need to retry the whole transaction.
  // The name comes from the `SELECT ... FOR UPDATE` SQL statement which is a locking read. Each `SELECT ... FOR UPDATE`
  // in a transaction will be assigned its own timestamp.
  uint64 for_update_ts = 6;
  // for executor to put extra data to store in lock
  bytes extra_data = 7;
}

message PessimisticLockResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  // if there are many keys can't be locked, there will be many txn_result, each txn_result is for one key
  // the txn_result is one of the following:
  // 1. LockInfo: lock meet a lock and can't proceed, the lock is returned
  // 2. WriteConflict: Write conflict with key which is already written after for_update_ts
  //    2.1 Optimistic: in optimistic transactions.
  //    2.2 PessimisticRetry: a lock acquisition request waits for a lock and awakes, or meets a newer version of data,
  //                           let Executor retry.
  //    2.3 SelfRolledBack: the transaction itself has been rolled back when it tries to prewrite.
  repeated TxnResultInfo txn_result = 2;
}

// Unlock keys locked using `PessimisticLockRequest`.
message PessimisticRollbackRequest {
  Context context = 1;
  uint64 start_ts = 2;
  uint64 for_update_ts = 3;
  repeated bytes keys = 4;
}

message PessimisticRollbackResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  repeated TxnResultInfo txn_result = 2;
}

message TxnPrewriteRequest {
  Context context = 1;
  // The data to be written to the database.
  repeated Mutation mutations = 2;
  // The primary lock of the transaction is setup by client
  bytes primary_lock = 3;
  // Identifies the transaction being written.
  int64 start_ts = 4;
  // the lock's ttl is timestamp in milisecond.
  int64 lock_ttl = 5;
  // the number of keys involved in the transaction
  int64 txn_size = 6;
  // When the transaction involves only one region, it's possible to commit the
  // transaction directly with 1PC protocol.
  bool try_one_pc = 7;  // NOT IMPLEMENTED
  // The max commit ts is reserved for limiting the commit ts of 1PC, which can be used to avoid inconsistency with
  // schema change. This field is unused now.
  int64 max_commit_ts = 8;  // NOT IMPLEMENTED
  int64 for_update_ts = 9;  // for pessimistic transaction
}

message TxnPrewriteResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  // for prewrite, txn_result will be one of the following:
  // 1. LockInfo: prewrite meet a lock and can't proceed, the lock is returned
  // 2. WriteConflict: Write conflict with key which is already written after start_ts
  //    2.1 Optimistic: in optimistic transactions.
  //    2.2 SelfRolledBack: the transaction itself has been rolled back when it tries to prewrite.
  // 3. otherwise, txn_result is empty
  // for success prewrite, txn_result is empty
  // for failure prewrite, txn_result is not empty
  // if txn_result is AlreadyExist, there will be many txn_result, each txn_result is for one key
  // if there is a WriteConflict in txn_result, client should backoff or cleanup the lock then retry
  repeated TxnResultInfo txn_result = 2;
  // if there is PutIfAbsent in mutation, and if there is key conflict, the conflict key will be returned
  repeated AlreadyExist keys_already_exist = 3;
  // When the transaction is successfully committed with 1PC protocol, this
  // field will be set to the commit ts of the transaction. Otherwise, if dingo-store
  // failed to commit it with 1PC or the transaction is not 1PC, the value will
  // be 0.
  int64 one_pc_commit_ts = 4;  // NOT IMPLEMENTED
}

message TxnCommitRequest {
  Context context = 1;
  // The start_ts of the transaction.
  int64 start_ts = 2;
  // The commit_ts of transaction. Must be greater than `start_ts`.
  int64 commit_ts = 3;
  // All keys in the transaction to be committed.
  repeated bytes keys = 4;
}

message TxnCommitResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  // the txn_result is one of the following:
  // 1. LockInfo: Commit meets a lock and can't proceed, the lock is returned
  // 2. TxnNotFound: if committing a key but not found its lock, the lock may be cleaned up by gc or resolved by. If
  // committing primary key meet this error, the transaction may be rolled back. If committing secondary key meet this,
  // Executor can think its lock is resolved, and continue to commit.
  // 3. otherwise, txn_result is empty
  TxnResultInfo txn_result = 2;
  // The commit_ts of the transaction.
  int64 commit_ts = 3;
}

// CheckTxnStatusRequest checks the status of a transaction.
// If the transaction is rollbacked/committed, return that result.
// If the TTL of the transaction is exhausted, abort that transaction and inform the caller.
// Otherwise, returns the TTL information for the transaction.
message TxnCheckTxnStatusRequest {
  Context context = 1;
  // Primary key and lock ts together to locate the primary lock of a transaction.
  bytes primary_key = 2;
  // Starting timestamp of the transaction being checked.
  int64 lock_ts = 3;
  // The start timestamp of the transaction which this request is part of.
  int64 caller_start_ts = 4;
  // The client must specify the current time to dingo-store using this timestamp.
  // It is used to check TTL timeouts. It may be inaccurate.
  int64 current_ts = 5;
}

message TxnCheckTxnStatusResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  // the txn_result is one of the following:
  // 1. PrimaryMismatch: CheckTxnStatus is sent to a lock that's not the primary.
  // 2. TxnNotFound: Txn not found when checking txn status.
  // 3. otherwise, txn_result is empty
  TxnResultInfo txn_result = 2;
  // Three kinds of transaction status:
  //   locked: lock_ttl > 0
  //   committed: commit_ts > 0
  //   rollbacked: lock_ttl = 0 && commit_ts = 0
  int64 lock_ttl = 3;
  // if the transaction of the lock is committed, the commit_ts is returned
  int64 commit_ts = 4;
  // The action performed by dingo-store (and why if the action is to rollback).
  Action action = 5;
  LockInfo lock_info = 6;
}

// For all keys locked by the transaction identified by `start_ts`, either
// commit or rollback the transaction and unlock the key.
message TxnResolveLockRequest {
  Context context = 1;
  int64 start_ts = 2;
  // `commit_ts == 0` means the transaction was rolled back.
  // `commit_ts > 0` means the transaction was committed at the given timestamp.
  int64 commit_ts = 3;
  // Only resolve specified keys.
  repeated bytes keys = 4;
}

message TxnResolveLockResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  // now the txn_result is not used, maybe used in the future
  TxnResultInfo txn_result = 2;
}

message TxnBatchGetRequest {
  Context context = 1;
  repeated bytes keys = 2;
  int64 start_ts = 3;
}

message TxnBatchGetResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  // This txn_result exists when some key is locked but we cannot check locks of
  // all keys. In this case, `kvs` should be empty and the client should redo
  // batch get all the keys after resolving the lock.
  // the txn_result is one of the following:
  // 1. LockInfo: Read conflict with key which is locked by another transaction. The client should backoff or cleanup
  // the lock then retry.
  // 2. otherwise, txn_result is empty
  TxnResultInfo txn_result = 2;
  // When some key is locked but we cannot check locks of
  // all keys. In this case, `kvs` should be empty and the client should redo
  // batch get all the keys after resolving the lock.
  repeated dingodb.pb.common.KeyValue kvs = 3;
}

// Rollback a prewritten transaction. This will remove the preliminary data from
// the database, unlock locks, and leave a rollback tombstone.
message TxnBatchRollbackRequest {
  Context context = 1;
  // Identify the transaction to be rolled back.
  int64 start_ts = 2;
  // The keys to rollback.
  repeated bytes keys = 3;
}

message TxnBatchRollbackResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  // the txn_result is one of the following:
  // 1. LockInfo: Commit meets a lock and can't proceed, the lock is returned
  // 2. otherwise, txn_result is empty
  TxnResultInfo txn_result = 2;
}

// Scan the database for locks. Used at the start of the GC process to find all
// old locks.
message TxnScanLockRequest {
  Context context = 1;
  // Returns all locks with a start timestamp before `max_ts`.
  int64 max_ts = 2;
  // Start scanning from this key.
  // if start_key is empty, means scan from the beginning of region
  bytes start_key = 3;
  // The maximum number of locks to return.
  uint32 limit = 4;
  // The exclusive upperbound for scanning.
  // if end_key is empty, means scan to the end of region
  bytes end_key = 5;
}

message TxnScanLockResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  TxnResultInfo txn_result = 2;
  // Info on all locks found by the scan.
  repeated LockInfo locks = 3;
}

// Update the lock_ttl of a large transaction to
// prevent it from been killed.
message TxnHeartBeatRequest {
  Context context = 1;
  // The key of the lock to update.
  bytes primary_lock = 2;
  // Start timestamp oracle of the large transaction.
  int64 start_ts = 3;
  // The new TTL the sender would like.
  // The advise_lock_ttl is the timestamp of milisecond.
  int64 advise_lock_ttl = 4;
}

message TxnHeartBeatResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  // the txn_result is one of the following:
  // 1. PrimaryMismatch: Heartbeat is sent to a lock that's not the primary.
  // 2. TxnNotFound: Txn not found when heartbeat.
  // 3. otherwise, txn_result is empty
  TxnResultInfo txn_result = 2;
  // The TTL actually set on the requested lock.
  int64 lock_ttl = 3;
}

// Request dingo-store to garbage collect all non-current data older than `safe_point_ts`.
message TxnGcRequest {
  Context context = 1;
  int64 safe_point_ts = 2;
}

message TxnGcResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  TxnResultInfo txn_result = 2;
}

// Delete a range of data from dingo-store.
// All keys in the range will be deleted permanently regardless of their
// timestamps. This means that deleted keys will not be retrievable by
// specifying an older timestamp.
// the range is [start_key, end_key)
message TxnDeleteRangeRequest {
  Context context = 1;
  bytes start_key = 2;
  bytes end_key = 3;
}

message TxnDeleteRangeResponse {
  // error code
  dingodb.pb.error.Error error = 1;
}

message TxnDataKey {
  bytes key = 1;
  int64 start_ts = 2;
}

message TxnDataValue {
  bytes value = 1;
}

message TxnLockKey {
  bytes key = 1;
}

message TxnLockValue {
  LockInfo lock_info = 1;
}

message TxnWriteKey {
  bytes key = 1;
  int64 commit_ts = 2;
}

message TxnWriteValue {
  WriteInfo write_info = 1;
}

message TxnDumpRequest {
  Context context = 1;
  // the range is [start_key, end_key)
  bytes start_key = 2;
  bytes end_key = 3;
  // the range is [start_ts, end_ts)
  // if start_ts == 0, means start from the beginning
  // if int64_MAX, means end to the end
  int64 start_ts = 4;
  int64 end_ts = 5;
}

message TxnDumpResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  TxnResultInfo txn_result = 2;

  // data key: raw_key | start_ts
  repeated TxnDataKey data_keys = 3;
  // data value: raw_value
  repeated TxnDataValue data_values = 4;
  // lock key: raw_key | lock_ver
  repeated TxnLockKey lock_keys = 5;
  // lock value: LockInfo
  repeated TxnLockValue lock_values = 6;
  // write key: raw_key | commit_ts
  repeated TxnWriteKey write_keys = 7;
  // write value: WriteInfo
  repeated TxnWriteValue write_values = 8;
}

message HelloRequest {
  Context context = 1;
  bool get_region_metrics = 2;
}

message HelloResponse {
  // error code
  dingodb.pb.error.Error error = 1;
  int64 region_count = 2;
  int64 region_leader_count = 3;
  repeated dingodb.pb.common.RegionMetrics region_metrics = 4;
}

service StoreService {
  rpc Hello(HelloRequest) returns (HelloResponse);
  // kv
  rpc KvGet(KvGetRequest) returns (KvGetResponse);
  rpc KvBatchGet(KvBatchGetRequest) returns (KvBatchGetResponse);
  rpc KvPut(KvPutRequest) returns (KvPutResponse);
  rpc KvBatchPut(KvBatchPutRequest) returns (KvBatchPutResponse);
  rpc KvPutIfAbsent(KvPutIfAbsentRequest) returns (KvPutIfAbsentResponse);
  rpc KvBatchPutIfAbsent(KvBatchPutIfAbsentRequest) returns (KvBatchPutIfAbsentResponse);
  rpc KvBatchDelete(KvBatchDeleteRequest) returns (KvBatchDeleteResponse);
  rpc KvDeleteRange(KvDeleteRangeRequest) returns (KvDeleteRangeResponse);
  rpc KvCompareAndSet(KvCompareAndSetRequest) returns (KvCompareAndSetResponse);
  rpc KvBatchCompareAndSet(KvBatchCompareAndSetRequest) returns (KvBatchCompareAndSetResponse);

  rpc KvScanBegin(KvScanBeginRequest) returns (KvScanBeginResponse);
  rpc KvScanContinue(KvScanContinueRequest) returns (KvScanContinueResponse);
  rpc KvScanRelease(KvScanReleaseRequest) returns (KvScanReleaseResponse);

  // txn rpcs
  rpc TxnGet(TxnGetRequest) returns (TxnGetResponse);
  rpc TxnBatchGet(TxnBatchGetRequest) returns (TxnBatchGetResponse);
  rpc TxnScan(TxnScanRequest) returns (TxnScanResponse);
  rpc TxnDump(TxnDumpRequest) returns (TxnDumpResponse);

  rpc TxnPessimisticLock(PessimisticLockRequest) returns (PessimisticLockResponse);
  rpc TxnPessimisticRollback(PessimisticRollbackRequest) returns (PessimisticRollbackResponse);
  rpc TxnPrewrite(TxnPrewriteRequest) returns (TxnPrewriteResponse);
  rpc TxnCommit(TxnCommitRequest) returns (TxnCommitResponse);
  rpc TxnCheckTxnStatus(TxnCheckTxnStatusRequest) returns (TxnCheckTxnStatusResponse);
  rpc TxnResolveLock(TxnResolveLockRequest) returns (TxnResolveLockResponse);
  rpc TxnBatchRollback(TxnBatchRollbackRequest) returns (TxnBatchRollbackResponse);
  rpc TxnScanLock(TxnScanLockRequest) returns (TxnScanLockResponse);
  rpc TxnHeartBeat(TxnHeartBeatRequest) returns (TxnHeartBeatResponse);
  rpc TxnGc(TxnGcRequest) returns (TxnGcResponse);
  rpc TxnDeleteRange(TxnDeleteRangeRequest) returns (TxnDeleteRangeResponse);
};
